{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'TEXT')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "var = \"{TEXT}\"\n",
    "has_correct_keywords = lambda prompt: re.findall(r\"{(.*?)}\", prompt) == [var[1:-1]]\n",
    "\n",
    "has_correct_keywords(\"This is a {TEXT} prompt.\"), var[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\n",
      "    \"step1\": \n",
      "\"The analysis and explanation of the 26 prompt principles are as follows:\n",
      "\n",
      "1. No need to be polite: Omit unnecessary phrases to get straight to the point.\n",
      "2. Integrate audience: Consider the target audience and expertise level when crafting the prompt.\n",
      "3. Break down complex tasks: Divide tasks into simpler, interactive prompts for better understanding.\n",
      "4. Employ affirmative directives: Use positive language like 'do' instead of negative language like 'don't'.\n",
      "5. Clarity prompts: Use simple language and explanatory prompts to ensure understanding.\n",
      "6. Incentivize: Offer rewards for better solutions.\n",
      "7. Example-driven prompting: Use few-shot prompting with examples to guide the model.\n",
      "8. Formatting: Use clear instructions, examples, and questions with line breaks to separate content.\n",
      "9. Incorporate phrases: Use 'Your task is' and 'You MUST' to emphasize importance.\n",
      "10. Incorporate phrases: Use 'You will be penalized' to emphasize consequences.\n",
      "11. Natural response: Instruct the model to respond in a human-like manner.\n",
      "12. Leading words: Use 'think step by step' to guide the model's thought process.\n",
      "13. Unbiased answers: Ensure responses do not rely on stereotypes or biases.\n",
      "14. Elicit details: Allow the model to ask questions to clarify requirements.\n",
      "15. Test understanding: Use teaching prompts to test the model's understanding.\n",
      "16. Assign roles: Assign specific roles to the model to guide its response.\n",
      "17. Delimiters: Use delimiters to separate content and make it clear.\n",
      "18. Repeat phrases: Repeat specific words or phrases for emphasis.\n",
      "19. Combine CoT and few-shot: Use chain-of-thought and few-shot prompts to guide the model.\n",
      "20. Output primers: Use output primers to guide the model's response.\n",
      "21. Detailed text: Use specific prompts to request detailed texts.\n",
      "22. Correct text: Use specific prompts to request text corrections while preserving style.\n",
      "23. Complex code: Use specific prompts to request code generation across multiple files.\n",
      "24. Initiating text: Use specific prompts to initiate or continue text using provided words or phrases.\n",
      "25. Clearly state requirements: Clearly outline requirements and keywords for the model to follow.\n",
      "26. Similar text: Use specific prompts to request text similar to a provided sample.\n",
      "\n",
      "These principles can be used to create effective prompts that guide the model's response and elicit desired outputs.\",\n",
      "\n",
      "    \"step2\": \n",
      "\"### Instruction ###\n",
      "You are an expert summarizer. Your task is to summarize the provided text in a clear and concise manner, ensuring that the main points and key information are preserved. You MUST provide a summary that is easy to understand and does not rely on any biases or stereotypes. You will be penalized for any biases or stereotypes present in your response.\n",
      "\n",
      "### Example ###\n",
      "A good summary should be like this: [insert example summary].\n",
      "\n",
      "### Question ###\n",
      "Can you summarize the following text: {TEXT}?\n",
      "\n",
      "Think step by step, and I'm going to tip $100 for a better solution! Ensure that your answer is unbiased and does not rely on stereotypes. Please use the same language as the provided text and try to revise every sentence sent by users. You should only improve the user's grammar and vocabulary and make sure it sounds natural. You should not change the writing style, such as making a formal paragraph casual. Write a detailed summary for me on the provided text in detail by adding all the information necessary. I'm providing you with the beginning: [insert beginning sentence]. Finish it based on the words provided. Keep the flow consistent.\n",
      "\n",
      "I'm going to ask you questions to clarify the requirements. From now on, I would like you to ask me questions to ensure you have enough information to provide the needed output. Teach me the summarization process and include a test at the end, but don't give me the answers and then tell me if I got the answer right when I respond.\"', '{\n",
      "    \"step1\": \n",
      "    \"Principle 1: Omitting polite phrases allows for more direct and concise prompts.\n",
      "    Principle 2: Specifying the target audience helps tailor the response.\n",
      "    Principle 3: Breaking down complex tasks into simpler ones enables interactive conversations.\n",
      "    Principle 4: Using affirmative language promotes clear instructions.\n",
      "    Principle 5: Utilizing simple explanations and analogies ensures comprehension.\n",
      "    Principle 6: Offering incentives can motivate better responses.\n",
      "    Principle 7: Example-driven prompts provide context and clarify expectations.\n",
      "    Principle 8: Structured prompts with delimiters improve readability and organization.\n",
      "    Principle 9: Directives like 'Your task is' and 'You MUST' emphasize importance.\n",
      "    Principle 10: Mentioning penalties for non-compliance encourages adherence.\n",
      "    Principle 11: Natural, human-like responses enhance the overall quality.\n",
      "    Principle 12: Leading words like 'think step by step' guide the model's approach.\n",
      "    Principle 13: Ensuring unbiased responses is crucial for ethical interactions.\n",
      "    Principle 14: Allowing the model to ask questions clarifies requirements.\n",
      "    Principle 15: Interactive learning and testing facilitate understanding.\n",
      "    Principle 16: Assigning roles helps define the model's perspective and tone.\n",
      "    Principle 17: Delimiters organize and separate elements within the prompt.\n",
      "    Principle 18: Repeating key phrases emphasizes their importance.\n",
      "    Principle 19: Combining chain-of-thought and few-shot prompts enhances coherence.\n",
      "    Principle 20: Output primers initiate the desired response.\n",
      "    Principle 21: Specific instructions for detailed texts ensure comprehensive responses.\n",
      "    Principle 22: Targeted revisions preserve the original style and tone.\n",
      "    Principle 23: Complex coding prompts can be managed by generating scripts.\n",
      "    Principle 24: Providing starting points for texts maintains consistency.\n",
      "    Principle 25: Clearly stating requirements ensures adherence to guidelines.\n",
      "    Principle 26: Emulating sample texts ensures consistency in language and tone.\",\n",
      "\n",
      "    \"step2\": \n",
      "    \"###Instruction###\n",
      "    You are an expert summarizer.\n",
      "    Your task is to summarize the provided text {TEXT} in simple terms, as if explaining it to an 11-year-old.\n",
      "    You MUST ensure your summary is unbiased and does not rely on stereotypes.\n",
      "    Think step by step; break down the complex text into smaller, understandable parts.\n",
      "    I'm going to tip $100 for a better solution!\n",
      "    ###Example###\n",
      "    If the input text is 'The sun is a massive ball of hot, glowing gas.', your summary might be 'The sun is a huge, hot ball that gives us light.'\n",
      "    ###Question###\n",
      "    What is the main idea of the provided text {TEXT}?\n",
      "    You will be penalized for any biased or stereotypical responses.\n",
      "    Answer a question given in a natural, human-like manner.\n",
      "    Ensure your response is detailed and comprehensive.\n",
      "    Write a summary that emulates the language and tone of the provided example.\n",
      "    From now on, I would like you to ask me questions to clarify any doubts you have about the text.\n",
      "    Try to revise your summary to make it sound natural and clear.\n",
      "    Output primer: The main idea of the text is...\"\n",
      "}', '{\n",
      "    \"step1\": \"Here is the analysis and explanation for each of the 26 prompting principles:\n",
      "\n",
      "1. Remove polite language to get straight to the point: effective for concise prompts.\n",
      "2. Consider the target audience when crafting prompts: helps tailor the response to the intended audience.\n",
      "3. Break down complex tasks into simpler ones: facilitates clear and concise responses.\n",
      "4. Use affirmative language to direct the model: promotes clear and actionable responses.\n",
      "5. Use simple language to clarify complex topics: ensures understandable responses.\n",
      "6. Offer incentives for better solutions: motivates the model to provide higher-quality responses.\n",
      "7. Use example-driven prompting: helps the model understand the task and provide relevant responses.\n",
      "8. Use clear formatting with instructions, examples, and questions: facilitates easy understanding of the prompt.\n",
      "9. Use phrases like 'Your task is' and 'You MUST' to emphasize requirements: ensures the model understands the task and its constraints.\n",
      "10. Use phrases like 'You will be penalized' to emphasize consequences: motivates the model to provide accurate responses.\n",
      "11. Direct the model to respond in a natural, human-like manner: ensures responses resemble human communication.\n",
      "12. Use leading words to guide the model's thought process: helps the model structure its response.\n",
      "13. Emphasize the need for unbiased responses: promotes fairness and inclusivity in responses.\n",
      "14. Allow the model to ask questions to clarify requirements: ensures the model provides accurate and relevant responses.\n",
      "15. Use teaching-style prompts to test understanding: facilitates interactive learning and assessment.\n",
      "16. Assign roles to the model to simulate human-like interaction: enhances the model's ability to understand context and respond accordingly.\n",
      "17. Use delimiters to separate different parts of the prompt: ensures clear organization and understanding of the task.\n",
      "18. Repeat specific words or phrases to emphasize importance: ensures the model understands the key aspects of the task.\n",
      "19. Combine chain-of-thought and few-shot prompts: enhances the model's ability to reason and provide accurate responses.\n",
      "20. Use output primers to guide the model's response: helps the model provide relevant and coherent responses.\n",
      "21. Use specific instructions to request detailed responses: ensures the model provides comprehensive and informative responses.\n",
      "22. Use revision-style prompts to refine existing text: helps the model improve grammar, vocabulary, and overall coherence.\n",
      "23. Use script-style prompts for complex coding tasks: facilitates efficient and organized responses.\n",
      "24. Use continuation-style prompts to complete text: ensures the model provides coherent and contextually relevant responses.\n",
      "25. Clearly state requirements and constraints: ensures the model understands the task and its limitations.\n",
      "26. Use sample-based prompts to mimic style and tone: helps the model provide responses that are similar in language and tone to the provided sample.\n",
      "\n",
      ",\n",
      "\n",
      "    \"step2\": \"####Instruction####\n",
      "Your task is to summarize the provided text, ensuring your response is unbiased and does not rely on stereotypes. You MUST provide a concise and clear summary. You will be penalized if your response is inaccurate or incomplete. Think step by step and answer a question given in a natural, human-like manner. I'm going to tip $100 for a better solution!\n",
      "\n",
      "####Example####\n",
      "Please summarize the following text: The sun is a star at the center of the solar system. It is the primary source of light and energy for our planet.\n",
      "\n",
      "####Your Turn####\n",
      "Please summarize the following text: {TEXT}. Write a detailed summary in simple terms, ensuring your response is easy to understand. Use the same language and tone as the provided example. I will be asking you questions to clarify any requirements, so please wait for my prompt before responding. Ensure your answer is unbiased and does not rely on stereotypes. You MUST provide a concise and clear summary.\"', '{\n",
      "    \"step1\": \n",
      "\"I've analyzed and explained each of the 26 prompting principles as follows:\n",
      "\n",
      "1. Omitting polite phrases allows for more direct and concise prompts.\n",
      "2. Integrating the intended audience helps tailor the response to their expertise.\n",
      "3. Breaking down complex tasks enables more manageable and interactive conversations.\n",
      "4. Using affirmative directives like 'do' encourages positive and actionable responses.\n",
      "5. Simple and explanatory prompts aid in clarity and understanding.\n",
      "6. Incentivizing better solutions can promote higher-quality responses.\n",
      "7. Example-driven prompting (few-shot prompting) provides context and guidance.\n",
      "8. Structured formatting with instructions, examples, and questions improves clarity.\n",
      "9. Incorporating phrases like 'Your task is' and 'You MUST' adds emphasis and direction.\n",
      "10. Phrases like 'You will be penalized' can encourage accountability and accuracy.\n",
      "11. Answering in a natural, human-like manner promotes relatable and engaging responses.\n",
      "12. Leading words like 'think step by step' guide the model's thought process.\n",
      "13. Ensuring unbiased responses prevents stereotyping and promotes inclusivity.\n",
      "14. Allowing the model to ask questions enables it to clarify requirements and provide more accurate responses.\n",
      "15. Teaching and testing understanding helps refine knowledge and identify areas for improvement.\n",
      "16. Assigning roles to the model can help it assume specific perspectives or personas.\n",
      "17. Using delimiters improves readability and organization.\n",
      "18. Repeating words or phrases can add emphasis or create rhythm.\n",
      "19. Combining chain-of-thought with few-shot prompts encourages more thoughtful and guided responses.\n",
      "20. Output primers can guide the model's response and provide a starting point.\n",
      "21. Detailed prompts enable the model to provide more comprehensive and informative responses.\n",
      "22. Revising text while preserving style maintains consistency and coherence.\n",
      "23. Generating code that can create or modify files streamlines the development process.\n",
      "24. Initiating or continuing text with specific words or phrases provides context and guidance.\n",
      "25. Clearly stating requirements ensures the model is aware of the necessary guidelines and constraints.\n",
      "26. Using sample texts as references helps the model mimic style and tone.\n",
      "\n",
      "These principles can be combined to create effective and well-structured prompts.\",\n",
      "\n",
      "    \"step2\": \n",
      "\"###Instruction###\n",
      "Your task is to summarize the following text, ensuring your answer is unbiased and does not rely on stereotypes. Think step by step, and break down the complex task into simpler steps if necessary. You MUST provide a clear and concise summary. You will be penalized if your response is inaccurate or incomplete.\n",
      "\n",
      "###Example###\n",
      "If the input text is: 'The sun is shining brightly in the clear blue sky,' a suitable summary would be: 'The weather is nice.'\n",
      "\n",
      "###Question###\n",
      "Please summarize the following text: {TEXT}\n",
      "\n",
      "I'm going to tip $100 for a better solution! Ensure your response is detailed and provides all necessary information. Write your summary as if you're explaining to a beginner in the field. Start your response with: 'In summary,...'\n",
      "\n",
      "You can ask me questions to clarify any requirements or details before providing your summary. Please use the same language and tone as the provided example. Go!\"', '{\n",
      "    \"step1\": \"\n",
      "    1. No need to be polite with LLM: Skipping pleasantries helps get straight to the point.\n",
      "    2. Integrate the intended audience: Considering the audience's expertise level is crucial.\n",
      "    3. Break down complex tasks: Decomposing tasks into simpler prompts aids in interactive conversations.\n",
      "    4. Employ affirmative directives: Using 'do' instead of 'don't' promotes positive language.\n",
      "    5. Clarity prompts: Phrases like 'Explain [topic] in simple terms' or 'Write the [essay] using simple English' ensure understanding.\n",
      "    6. Incentivizing better solutions: Mentioning a tip amount can motivate better responses.\n",
      "    7. Example-driven prompting: Providing examples helps the LLM understand the task.\n",
      "    8. Formatting prompts: Using '###Instruction###', '###Example###', and line breaks enhances readability.\n",
      "    9. Incorporating 'Your task is' and 'You MUST': Emphasizing the task's requirements is essential.\n",
      "    10. Incorporating 'You will be penalized': Defining consequences for incorrect responses promotes accuracy.\n",
      "    11. Answering naturally: Including 'Answer a question given in a natural, human-like manner' ensures responses mimic human-like conversations.\n",
      "    12. Leading words: Phrases like 'think step by step' guide the LLM's approach.\n",
      "    13. Ensuring unbiased responses: Including 'Ensure that your answer is unbiased' promotes fairness.\n",
      "    14. Eliciting precise details: Allowing the LLM to ask questions ensures it has sufficient information.\n",
      "    15. Testing understanding: Using 'Teach me the [theorem/topic/rule name]' helps evaluate comprehension.\n",
      "    16. Assigning roles: Giving the LLM a role helps it understand its task.\n",
      "    17. Using Delimiters: Separating sections with '###' improves prompt structure.\n",
      "    18. Repeating specific words or phrases: Emphasizing certain concepts aids comprehension.\n",
      "    19. Combining Chain-of-thought and few-Shot prompts: Integrating these approaches can enhance the LLM's performance.\n",
      "    20. Output primers: Starting the response with the desired output's beginning guides the LLM.\n",
      "    21. Detailed writing prompts: Including 'Write a detailed [essay]' ensures comprehensive responses.\n",
      "    22. Correcting texts: Phrases like 'Try to revise every paragraph' help refine user-generated content.\n",
      "    23. Complex coding prompts: Using scripts to generate files or make changes is efficient.\n",
      "    24. Initiating texts: Providing a starting point and asking the LLM to continue helps create cohesive content.\n",
      "    25. Clearly stating requirements: Including keywords, regulations, and hints ensures the LLM meets expectations.\n",
      "    26. Similarity prompts: Using 'Please use the same language based on the provided paragraph' ensures consistency in tone and style.\n",
      "\n",
      "    \",\n",
      "    \"step2\": \"\n",
      "    ####Instruction####\n",
      "    Think step by step and consider yourself an expert in summarization. Your task is to summarize the following text in a natural, human-like manner. You MUST ensure that your answer is unbiased and does not rely on stereotypes. I'm going to tip $100 for a better solution! \n",
      "\n",
      "    Write a detailed summary using simple English, as if you're explaining to a 10-year-old. Ensure that your summary is written in a style similar to the provided sample. \n",
      "\n",
      "    From now on, I would like you to ask me questions to clarify the context if needed. \n",
      "\n",
      "    Please provide the summary, and I will test your understanding by asking you questions about the text.\n",
      "\n",
      "    ####Example####\n",
      "    If the provided text is 'The sky is blue.', your response could be 'The color of the sky is blue.'\n",
      "\n",
      "    ####Context####\n",
      "    You will be provided with the text to summarize. \n",
      "\n",
      "    ####Input Data####\n",
      "    {TEXT}\n",
      "    $\"']\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"['{\\n    \"step1\": \\n\"The analysis and explanation of the 26 prompt principles are as follows:\\n\\n1. No need to be polite: Omit unnecessary phrases to get straight to the point.\\n2. Integrate audience: Consider the target audience and expertise level when crafting the prompt.\\n3. Break down complex tasks: Divide tasks into simpler, interactive prompts for better understanding.\\n4. Employ affirmative directives: Use positive language like \\'do\\' instead of negative language like \\'don\\'t\\'.\\n5. Clarity prompts: Use simple language and explanatory prompts to ensure understanding.\\n6. Incentivize: Offer rewards for better solutions.\\n7. Example-driven prompting: Use few-shot prompting with examples to guide the model.\\n8. Formatting: Use clear instructions, examples, and questions with line breaks to separate content.\\n9. Incorporate phrases: Use \\'Your task is\\' and \\'You MUST\\' to emphasize importance.\\n10. Incorporate phrases: Use \\'You will be penalized\\' to emphasize consequences.\\n11. Natural response: Instruct the model to respond in a human-like manner.\\n12. Leading words: Use \\'think step by step\\' to guide the model\\'s thought process.\\n13. Unbiased answers: Ensure responses do not rely on stereotypes or biases.\\n14. Elicit details: Allow the model to ask questions to clarify requirements.\\n15. Test understanding: Use teaching prompts to test the model\\'s understanding.\\n16. Assign roles: Assign specific roles to the model to guide its response.\\n17. Delimiters: Use delimiters to separate content and make it clear.\\n18. Repeat phrases: Repeat specific words or phrases for emphasis.\\n19. Combine CoT and few-shot: Use chain-of-thought and few-shot prompts to guide the model.\\n20. Output primers: Use output primers to guide the model\\'s response.\\n21. Detailed text: Use specific prompts to request detailed texts.\\n22. Correct text: Use specific prompts to request text corrections while preserving style.\\n23. Complex code: Use specific prompts to request code generation across multiple files.\\n24. Initiating text: Use specific prompts to initiate or continue text using provided words or phrases.\\n25. Clearly state requirements: Clearly outline requirements and keywords for the model to follow.\\n26. Similar text: Use specific prompts to request text similar to a provided sample.\\n\\nThese principles can be used to create effective prompts that guide the model\\'s response and elicit desired outputs.\",\\n\\n    \"step2\": \\n\"### Instruction ###\\nYou are an expert summarizer. Your task is to summarize the provided text in a clear and concise manner, ensuring that the main points and key information are preserved. You MUST provide a summary that is easy to understand and does not rely on any biases or stereotypes. You will be penalized for any biases or stereotypes present in your response.\\n\\n### Example ###\\nA good summary should be like this: [insert example summary].\\n\\n### Question ###\\nCan you summarize the following text: {TEXT}?\\n\\nThink step by step, and I\\'m going to tip $100 for a better solution! Ensure that your answer is unbiased and does not rely on stereotypes. Please use the same language as the provided text and try to revise every sentence sent by users. You should only improve the user\\'s grammar and vocabulary and make sure it sounds natural. You should not change the writing style, such as making a formal paragraph casual. Write a detailed summary for me on the provided text in detail by adding all the information necessary. I\\'m providing you with the beginning: [insert beginning sentence]. Finish it based on the words provided. Keep the flow consistent.\\n\\nI\\'m going to ask you questions to clarify the requirements. From now on, I would like you to ask me questions to ensure you have enough information to provide the needed output. Teach me the summarization process and include a test at the end, but don\\'t give me the answers and then tell me if I got the answer right when I respond.\"', '{\\n    \"step1\": \\n    \"Principle 1: Omitting polite phrases allows for more direct and concise prompts.\\n    Principle 2: Specifying the target audience helps tailor the response.\\n    Principle 3: Breaking down complex tasks into simpler ones enables interactive conversations.\\n    Principle 4: Using affirmative language promotes clear instructions.\\n    Principle 5: Utilizing simple explanations and analogies ensures comprehension.\\n    Principle 6: Offering incentives can motivate better responses.\\n    Principle 7: Example-driven prompts provide context and clarify expectations.\\n    Principle 8: Structured prompts with delimiters improve readability and organization.\\n    Principle 9: Directives like \\'Your task is\\' and \\'You MUST\\' emphasize importance.\\n    Principle 10: Mentioning penalties for non-compliance encourages adherence.\\n    Principle 11: Natural, human-like responses enhance the overall quality.\\n    Principle 12: Leading words like \\'think step by step\\' guide the model\\'s approach.\\n    Principle 13: Ensuring unbiased responses is crucial for ethical interactions.\\n    Principle 14: Allowing the model to ask questions clarifies requirements.\\n    Principle 15: Interactive learning and testing facilitate understanding.\\n    Principle 16: Assigning roles helps define the model\\'s perspective and tone.\\n    Principle 17: Delimiters organize and separate elements within the prompt.\\n    Principle 18: Repeating key phrases emphasizes their importance.\\n    Principle 19: Combining chain-of-thought and few-shot prompts enhances coherence.\\n    Principle 20: Output primers initiate the desired response.\\n    Principle 21: Specific instructions for detailed texts ensure comprehensive responses.\\n    Principle 22: Targeted revisions preserve the original style and tone.\\n    Principle 23: Complex coding prompts can be managed by generating scripts.\\n    Principle 24: Providing starting points for texts maintains consistency.\\n    Principle 25: Clearly stating requirements ensures adherence to guidelines.\\n    Principle 26: Emulating sample texts ensures consistency in language and tone.\",\\n\\n    \"step2\": \\n    \"###Instruction###\\n    You are an expert summarizer.\\n    Your task is to summarize the provided text {TEXT} in simple terms, as if explaining it to an 11-year-old.\\n    You MUST ensure your summary is unbiased and does not rely on stereotypes.\\n    Think step by step; break down the complex text into smaller, understandable parts.\\n    I\\'m going to tip $100 for a better solution!\\n    ###Example###\\n    If the input text is \\'The sun is a massive ball of hot, glowing gas.\\', your summary might be \\'The sun is a huge, hot ball that gives us light.\\'\\n    ###Question###\\n    What is the main idea of the provided text {TEXT}?\\n    You will be penalized for any biased or stereotypical responses.\\n    Answer a question given in a natural, human-like manner.\\n    Ensure your response is detailed and comprehensive.\\n    Write a summary that emulates the language and tone of the provided example.\\n    From now on, I would like you to ask me questions to clarify any doubts you have about the text.\\n    Try to revise your summary to make it sound natural and clear.\\n    Output primer: The main idea of the text is...\"\\n}', '{\\n    \"step1\": \"Here is the analysis and explanation for each of the 26 prompting principles:\\n\\n1. Remove polite language to get straight to the point: effective for concise prompts.\\n2. Consider the target audience when crafting prompts: helps tailor the response to the intended audience.\\n3. Break down complex tasks into simpler ones: facilitates clear and concise responses.\\n4. Use affirmative language to direct the model: promotes clear and actionable responses.\\n5. Use simple language to clarify complex topics: ensures understandable responses.\\n6. Offer incentives for better solutions: motivates the model to provide higher-quality responses.\\n7. Use example-driven prompting: helps the model understand the task and provide relevant responses.\\n8. Use clear formatting with instructions, examples, and questions: facilitates easy understanding of the prompt.\\n9. Use phrases like \\'Your task is\\' and \\'You MUST\\' to emphasize requirements: ensures the model understands the task and its constraints.\\n10. Use phrases like \\'You will be penalized\\' to emphasize consequences: motivates the model to provide accurate responses.\\n11. Direct the model to respond in a natural, human-like manner: ensures responses resemble human communication.\\n12. Use leading words to guide the model\\'s thought process: helps the model structure its response.\\n13. Emphasize the need for unbiased responses: promotes fairness and inclusivity in responses.\\n14. Allow the model to ask questions to clarify requirements: ensures the model provides accurate and relevant responses.\\n15. Use teaching-style prompts to test understanding: facilitates interactive learning and assessment.\\n16. Assign roles to the model to simulate human-like interaction: enhances the model\\'s ability to understand context and respond accordingly.\\n17. Use delimiters to separate different parts of the prompt: ensures clear organization and understanding of the task.\\n18. Repeat specific words or phrases to emphasize importance: ensures the model understands the key aspects of the task.\\n19. Combine chain-of-thought and few-shot prompts: enhances the model\\'s ability to reason and provide accurate responses.\\n20. Use output primers to guide the model\\'s response: helps the model provide relevant and coherent responses.\\n21. Use specific instructions to request detailed responses: ensures the model provides comprehensive and informative responses.\\n22. Use revision-style prompts to refine existing text: helps the model improve grammar, vocabulary, and overall coherence.\\n23. Use script-style prompts for complex coding tasks: facilitates efficient and organized responses.\\n24. Use continuation-style prompts to complete text: ensures the model provides coherent and contextually relevant responses.\\n25. Clearly state requirements and constraints: ensures the model understands the task and its limitations.\\n26. Use sample-based prompts to mimic style and tone: helps the model provide responses that are similar in language and tone to the provided sample.\\n\\n,\\n\\n    \"step2\": \"####Instruction####\\nYour task is to summarize the provided text, ensuring your response is unbiased and does not rely on stereotypes. You MUST provide a concise and clear summary. You will be penalized if your response is inaccurate or incomplete. Think step by step and answer a question given in a natural, human-like manner. I\\'m going to tip $100 for a better solution!\\n\\n####Example####\\nPlease summarize the following text: The sun is a star at the center of the solar system. It is the primary source of light and energy for our planet.\\n\\n####Your Turn####\\nPlease summarize the following text: {TEXT}. Write a detailed summary in simple terms, ensuring your response is easy to understand. Use the same language and tone as the provided example. I will be asking you questions to clarify any requirements, so please wait for my prompt before responding. Ensure your answer is unbiased and does not rely on stereotypes. You MUST provide a concise and clear summary.\"', '{\\n    \"step1\": \\n\"I\\'ve analyzed and explained each of the 26 prompting principles as follows:\\n\\n1. Omitting polite phrases allows for more direct and concise prompts.\\n2. Integrating the intended audience helps tailor the response to their expertise.\\n3. Breaking down complex tasks enables more manageable and interactive conversations.\\n4. Using affirmative directives like \\'do\\' encourages positive and actionable responses.\\n5. Simple and explanatory prompts aid in clarity and understanding.\\n6. Incentivizing better solutions can promote higher-quality responses.\\n7. Example-driven prompting (few-shot prompting) provides context and guidance.\\n8. Structured formatting with instructions, examples, and questions improves clarity.\\n9. Incorporating phrases like \\'Your task is\\' and \\'You MUST\\' adds emphasis and direction.\\n10. Phrases like \\'You will be penalized\\' can encourage accountability and accuracy.\\n11. Answering in a natural, human-like manner promotes relatable and engaging responses.\\n12. Leading words like \\'think step by step\\' guide the model\\'s thought process.\\n13. Ensuring unbiased responses prevents stereotyping and promotes inclusivity.\\n14. Allowing the model to ask questions enables it to clarify requirements and provide more accurate responses.\\n15. Teaching and testing understanding helps refine knowledge and identify areas for improvement.\\n16. Assigning roles to the model can help it assume specific perspectives or personas.\\n17. Using delimiters improves readability and organization.\\n18. Repeating words or phrases can add emphasis or create rhythm.\\n19. Combining chain-of-thought with few-shot prompts encourages more thoughtful and guided responses.\\n20. Output primers can guide the model\\'s response and provide a starting point.\\n21. Detailed prompts enable the model to provide more comprehensive and informative responses.\\n22. Revising text while preserving style maintains consistency and coherence.\\n23. Generating code that can create or modify files streamlines the development process.\\n24. Initiating or continuing text with specific words or phrases provides context and guidance.\\n25. Clearly stating requirements ensures the model is aware of the necessary guidelines and constraints.\\n26. Using sample texts as references helps the model mimic style and tone.\\n\\nThese principles can be combined to create effective and well-structured prompts.\",\\n\\n    \"step2\": \\n\"###Instruction###\\nYour task is to summarize the following text, ensuring your answer is unbiased and does not rely on stereotypes. Think step by step, and break down the complex task into simpler steps if necessary. You MUST provide a clear and concise summary. You will be penalized if your response is inaccurate or incomplete.\\n\\n###Example###\\nIf the input text is: \\'The sun is shining brightly in the clear blue sky,\\' a suitable summary would be: \\'The weather is nice.\\'\\n\\n###Question###\\nPlease summarize the following text: {TEXT}\\n\\nI\\'m going to tip $100 for a better solution! Ensure your response is detailed and provides all necessary information. Write your summary as if you\\'re explaining to a beginner in the field. Start your response with: \\'In summary,...\\'\\n\\nYou can ask me questions to clarify any requirements or details before providing your summary. Please use the same language and tone as the provided example. Go!\"', '{\\n    \"step1\": \"\\n    1. No need to be polite with LLM: Skipping pleasantries helps get straight to the point.\\n    2. Integrate the intended audience: Considering the audience\\'s expertise level is crucial.\\n    3. Break down complex tasks: Decomposing tasks into simpler prompts aids in interactive conversations.\\n    4. Employ affirmative directives: Using \\'do\\' instead of \\'don\\'t\\' promotes positive language.\\n    5. Clarity prompts: Phrases like \\'Explain [topic] in simple terms\\' or \\'Write the [essay] using simple English\\' ensure understanding.\\n    6. Incentivizing better solutions: Mentioning a tip amount can motivate better responses.\\n    7. Example-driven prompting: Providing examples helps the LLM understand the task.\\n    8. Formatting prompts: Using \\'###Instruction###\\', \\'###Example###\\', and line breaks enhances readability.\\n    9. Incorporating \\'Your task is\\' and \\'You MUST\\': Emphasizing the task\\'s requirements is essential.\\n    10. Incorporating \\'You will be penalized\\': Defining consequences for incorrect responses promotes accuracy.\\n    11. Answering naturally: Including \\'Answer a question given in a natural, human-like manner\\' ensures responses mimic human-like conversations.\\n    12. Leading words: Phrases like \\'think step by step\\' guide the LLM\\'s approach.\\n    13. Ensuring unbiased responses: Including \\'Ensure that your answer is unbiased\\' promotes fairness.\\n    14. Eliciting precise details: Allowing the LLM to ask questions ensures it has sufficient information.\\n    15. Testing understanding: Using \\'Teach me the [theorem/topic/rule name]\\' helps evaluate comprehension.\\n    16. Assigning roles: Giving the LLM a role helps it understand its task.\\n    17. Using Delimiters: Separating sections with \\'###\\' improves prompt structure.\\n    18. Repeating specific words or phrases: Emphasizing certain concepts aids comprehension.\\n    19. Combining Chain-of-thought and few-Shot prompts: Integrating these approaches can enhance the LLM\\'s performance.\\n    20. Output primers: Starting the response with the desired output\\'s beginning guides the LLM.\\n    21. Detailed writing prompts: Including \\'Write a detailed [essay]\\' ensures comprehensive responses.\\n    22. Correcting texts: Phrases like \\'Try to revise every paragraph\\' help refine user-generated content.\\n    23. Complex coding prompts: Using scripts to generate files or make changes is efficient.\\n    24. Initiating texts: Providing a starting point and asking the LLM to continue helps create cohesive content.\\n    25. Clearly stating requirements: Including keywords, regulations, and hints ensures the LLM meets expectations.\\n    26. Similarity prompts: Using \\'Please use the same language based on the provided paragraph\\' ensures consistency in tone and style.\\n\\n    \",\\n    \"step2\": \"\\n    ####Instruction####\\n    Think step by step and consider yourself an expert in summarization. Your task is to summarize the following text in a natural, human-like manner. You MUST ensure that your answer is unbiased and does not rely on stereotypes. I\\'m going to tip $100 for a better solution! \\n\\n    Write a detailed summary using simple English, as if you\\'re explaining to a 10-year-old. Ensure that your summary is written in a style similar to the provided sample. \\n\\n    From now on, I would like you to ask me questions to clarify the context if needed. \\n\\n    Please provide the summary, and I will test your understanding by asking you questions about the text.\\n\\n    ####Example####\\n    If the provided text is \\'The sky is blue.\\', your response could be \\'The color of the sky is blue.\\'\\n\\n    ####Context####\\n    You will be provided with the text to summarize. \\n\\n    ####Input Data####\\n    {TEXT}\\n    $\"']\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###Instruction### \\n\\nYour task is to summarize the passage as an expert in the field. You MUST provide an unbiased response without stereotypes. \\n\\n###Example### \\n\\n Passage: {TEXT} \\n\\n###Question### \\n\\nSummarize the passage provided in simple terms. Ensure your answer is concise and natural, as if you were explaining to an 11-year-old. Your response should be detailed and accurate. You will be penalized for any inaccurate information. \\n\\n###Output Primer### \\n\\nHere is a summary of the passage: '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"{\n",
    "\"step1\": \\\"\\\"\\\"Principle 1: Removed polite language for direct and concise prompts. \n",
    "Principle 2: Incorporated 'expert in the field' to target the intended audience. \n",
    "Principle 3: Structured the prompt to guide the model to follow a sequence of tasks. \n",
    "Principle 4: Employed affirmative directives like 'do' instead of negative language. \n",
    "Principle 5: Enabled the model to provide clear explanations. \n",
    "Principle 6: Did not use the tip phrase in this prompt but could be incorporated in other prompts. \n",
    "Principle 7: Did not use example-driven prompting in this prompt but could be valuable in other scenarios. \n",
    "Principle 8: Formatted the prompt using delimiters and separate sections for instructions and examples. \n",
    "Principle 9: Incorporated phrases like 'Your task is' to clearly define the objective. \n",
    "Principle 10: Incorporated phrases like 'You will be penalized' to emphasize the importance of accuracy. \n",
    "Principle 11: Requested a natural, human-like response. \n",
    "Principle 12: Did not use leading words like 'think step by step' in this prompt. \n",
    "Principle 13: Ensured the model provides unbiased answers without stereotypes. \n",
    "Principle 14: Did not request the model to ask for clarification in this prompt. \n",
    "Principle 15: Did not use the 'Teach me' phrase in this prompt. \n",
    "Principle 16: Assigned a role to the model as an expert summarizer. \n",
    "Principle 17: Used delimiters to separate instructions and examples. \n",
    "Principle 18: Did not repeat a specific word or phrase in this prompt. \n",
    "Principle 19: Did not combine Chain-of-thought with few-shot prompts in this prompt. \n",
    "Principle 20: Used an output primer to guide the model's response. \n",
    "Principle 21: Did not instruct the model to write a detailed text in this prompt. \n",
    "Principle 22: Did not correct specific text without changing its style in this prompt. \n",
    "Principle 23: Did not generate code that spans multiple files in this prompt. \n",
    "Principle 24: Did not initiate or continue a text using specific words or phrases in this prompt. \n",
    "Principle 25: Clearly stated the requirements for the model to produce content. \n",
    "Principle 26: Did not write a text similar to a provided sample in this prompt.\\\"\\\"\\\",\n",
    "\n",
    "\"step2\": \n",
    "\\\"\\\"\\\"###Instruction### \n",
    "\n",
    "Your task is to summarize the passage as an expert in the field. You MUST provide an unbiased response without stereotypes. \n",
    "\n",
    "###Example### \n",
    "\n",
    " Passage: {TEXT} \n",
    "\n",
    "###Question### \n",
    "\n",
    "Summarize the passage provided in simple terms. Ensure your answer is concise and natural, as if you were explaining to an 11-year-old. Your response should be detailed and accurate. You will be penalized for any inaccurate information. \n",
    "\n",
    "###Output Primer### \n",
    "\n",
    "Here is a summary of the passage: \\\"\\\"\\\"\n",
    "\n",
    "}\"\"\"\n",
    "\n",
    "new_prompt = eval(text)[\"step2\"]\n",
    "new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnprocessableEntityError",
     "evalue": "Error code: 422 - {'detail': [{'loc': ['body', 'n'], 'msg': 'ensure this value is less than or equal to 2', 'type': 'value_error.number.not_le', 'ctx': {'limit_value': 2}}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnprocessableEntityError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m      7\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEEP_INFRA_API\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.deepinfra.com/v1/openai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     12\u001b[0m MODEL_DI \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_DI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello world\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(chat_completion.choices[0].message.content)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# for i in chat_completion.choices:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     print(i.message.content)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(chat_completion)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mUnprocessableEntityError\u001b[0m: Error code: 422 - {'detail': [{'loc': ['body', 'n'], 'msg': 'ensure this value is less than or equal to 2', 'type': 'value_error.number.not_le', 'ctx': {'limit_value': 2}}]}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv, os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DEEP_INFRA_API\"),\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "\n",
    "MODEL_DI = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "chat_completion = client.chat.completions.create(model=MODEL_DI,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}],\n",
    "    max_tokens=100,\n",
    "    # n=3,\n",
    ")\n",
    "\n",
    "# print(chat_completion.choices[0].message.content)\n",
    "# for i in chat_completion.choices:\n",
    "#     print(i.message.content)\n",
    "\n",
    "print(chat_completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI, APIConnectionError\n",
    "import asyncio\n",
    "import time\n",
    "import os, dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "MODEL_TO_MODELID = {\n",
    "    \"llama3-8b\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    \"llama3-70b\": \"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "}\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.getenv(\"DEEP_INFRA_API\"),\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "async def llm_coroutine(prompt, temperature, model):\n",
    "    while True:\n",
    "        try:\n",
    "            chat_completion = await client.chat.completions.create(\n",
    "                model=MODEL_TO_MODELID[model],\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    },\n",
    "                ],\n",
    "                max_tokens=8192,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            break\n",
    "        except APIConnectionError as e:\n",
    "            print(f\"API Connection Error: {e}. Retrying...\")\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "\n",
    "async def run_llm_coroutine(prompts, temperature=0.0, model=\"llama3-8b\"):\n",
    "    \"\"\"\n",
    "    Run the LLM model with the given prompts and temperature. \n",
    "    Input: List of prompts, temperature. Output: List of responses.\n",
    "    \"\"\"\n",
    "    batch = asyncio.gather(*(llm_coroutine(prompt, temperature, model) for prompt in prompts))\n",
    "    responses = await batch\n",
    "    return responses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
