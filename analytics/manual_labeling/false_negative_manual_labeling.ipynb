{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset, shuffle dataset and grab all rows in dataset with no prompts\n",
    "no_prompts_dataset = load_dataset(\"pisterlabs/promptset\").filter(lambda x: len(x[\"prompts\"]) == 0).shuffle(seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from llmebench.datasets import OSACT4SubtaskBDataset\n",
      "from llmebench.models import OpenAIModel\n",
      "from llmebench.tasks import HateSpeechTask\n",
      "\n",
      "\n",
      "def metadata():\n",
      "    return {\n",
      "        \"author\": \"Arabic Language Technologies, QCRI, HBKU\",\n",
      "        \"model\": \"gpt-4-32k (version 0314)\",\n",
      "        \"description\": \"GPT4 32k tokens model hosted on Azure, using the ChatCompletion API. API version '2023-03-15-preview'.\",\n",
      "        \"scores\": {\"Macro-F1\": \"0.669\"},\n",
      "    }\n",
      "\n",
      "\n",
      "def config():\n",
      "    return {\n",
      "        \"dataset\": OSACT4SubtaskBDataset,\n",
      "        \"task\": HateSpeechTask,\n",
      "        \"model\": OpenAIModel,\n",
      "        \"model_args\": {\n",
      "            \"class_labels\": [\"HS\", \"NOT_HS\"],\n",
      "            \"max_tries\": 3,\n",
      "        },\n",
      "    }\n",
      "\n",
      "\n",
      "def prompt(input_sample):\n",
      "    return [\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": \"You are an expert annotator, you can identify and label hate speech content within a tweet.\",\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": f'Given the following tweet, label it as \"HS\" or \"NOT_HS\" based on the content of the tweet: \\n {input_sample}',\n",
      "        },\n",
      "    ]\n",
      "\n",
      "\n",
      "def post_process(response):\n",
      "    out = response[\"choices\"][0][\"message\"][\"content\"]\n",
      "    j = out.find(\".\")\n",
      "    if j > 0:\n",
      "        out = out[0:j]\n",
      "\n",
      "    if \"not_hate_speech\" in out or \"no_hate_speech\" in out or \"NOT_HS\" == out:\n",
      "        out = \"NOT_HS\"\n",
      "    elif \"hate_speech\" in out or \"HS\" == out:\n",
      "        out = \"HS\"\n",
      "    else:\n",
      "        out = None\n",
      "    return out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(no_prompts_dataset[\"train\"][idx][\"file_contents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 4\n",
      "TN: 47\n",
      "% FN: 7.8431372549019605\n"
     ]
    }
   ],
   "source": [
    "# RANDOM SEED: 9\n",
    "\n",
    "FN=[8,24,37,50]\n",
    "TN=[0,1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36,38,39,40,41,42,43,44,45,46,47,48,49]\n",
    "print(f\"FN: {len(FN)}\")  # 4\n",
    "print(f\"TN: {len(TN)}\")  # 47\n",
    "print(f\"% FN: {len(FN)/(len(FN)+len(TN)) * 100}\")  # 7.84%\n",
    "\n",
    "# FN Indicators:\n",
    "#   co.generate(model='aa42cd3e-3154-4904-9c79-f2cbea2a3c74-ft',prompt=full_text)\n",
    "#   client.beta.assistants.create(name=\"Math Tutor\",instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",tools=[{\"type\": \"code_interpreter\"}],model=\"gpt-4-1106-preview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 7\n",
      "TN: 43\n",
      "% FN: 14.000000000000002\n"
     ]
    }
   ],
   "source": [
    "# RANDOM SEED: 25\n",
    "\n",
    "FN=[2,3,7,27,41,43,45]\n",
    "TN=[0,1,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28,29,30,31,32,33,34,35,36,37,38,39,40,42,44,46,47,48,49]\n",
    "print(f\"FN: {len(FN)}\")  # 7\n",
    "print(f\"TN: {len(TN)}\")  # 43\n",
    "print(f\"% FN: {len(FN)/(len(FN)+len(TN)) * 100}\")  # 14%\n",
    "\n",
    "# FN Indicators:\n",
    "#   openai.get_chat_response(chat_id=chat_id, query='напиши рандомний пост українською')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 12\n",
      "TN: 39\n",
      "% FN: 23.52941176470588\n"
     ]
    }
   ],
   "source": [
    "# RANDOM SEED: 2001\n",
    "\n",
    "FN=[5,7,9,10,13,20,31,33,37,45,47,50]\n",
    "TN=[0,1,2,3,4,6,8,11,12,14,15,16,17,18,19,21,22,23,24,25,26,27,28,29,30,32,34,35,36,38,39,40,41,42,43,44,46,48,49]\n",
    "print(f\"FN: {len(FN)}\")  # 12\n",
    "print(f\"TN: {len(TN)}\")  # 39\n",
    "print(f\"% FN: {len(FN)/(len(FN)+len(TN)) * 100}\")  # 23.53%\n",
    "\n",
    "# FN Indicators:\n",
    "#   content\n",
    "#   openai.ChatCompletion.create\n",
    "#   openai.chat.completions.create\n",
    "#   HumanMessage(content=observation)\n",
    "#   SystemMessage(content=load_prompt(\"critic\"))\n",
    "#   Custom Schema (2)\n",
    "#   messages\n",
    "#   wrapper function kwargs\n",
    "#   guidance(\"\"\"...\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
